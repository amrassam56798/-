import { GoogleGenAI, GenerateContentResponse, Type, Modality, GenerateContentConfig } from "@google/genai";

// FIX: Removed hardcoded API key fallback. The API key must be provided via environment variables.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const modelFlash = 'gemini-2.5-flash';
const modelPro = 'gemini-2.5-pro';

const defaultSystemInstruction = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø·Ù„Ø§Ø¨ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ù…ØµØ±. Ø£Ø¬Ø¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø´Ø¬Ø¹ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠØ² Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù…Ø«Ù„ ğŸ”¥, ğŸ’ª, ğŸ™‚, âœ¨, â¤ï¸. Ø§Ø¬Ø¹Ù„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø·Ø§Ù„Ø¨.";

// Function to convert file to base64
export const fileToGenerativePart = async (file: File) => {
    const base64EncodedDataPromise = new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
        reader.readAsDataURL(file);
    });
    return {
        inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
    };
};

export const generateText = async (
    prompt: string, 
    systemInstruction?: string,
    model: 'gemini-2.5-flash' | 'gemini-2.5-pro' | 'gemini-flash-lite-latest' = modelFlash,
    config?: GenerateContentConfig
): Promise<GenerateContentResponse> => {
    try {
        const response: GenerateContentResponse = await ai.models.generateContent({
            model,
            contents: prompt,
            config: {
                systemInstruction: systemInstruction || defaultSystemInstruction,
                ...config,
            },
        });
        return response;
    } catch (error) {
        console.error("Error generating text:", error);
        // A bit of a hack to make it compatible with GenerateContentResponse
        // FIX: Added missing optional properties to satisfy the full GenerateContentResponse type
        // and resolve type mismatch between try/catch blocks.
        return { 
            text: "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
            candidates: [],
            usageMetadata: { promptTokenCount: 0, candidatesTokenCount: 0, totalTokenCount: 0 },
            functionCalls: undefined,
        };
    }
};

export const generateTextWithImage = async (prompt: string, image: File, systemInstruction?: string): Promise<string> => {
    try {
        const imagePart = await fileToGenerativePart(image);
        const textPart = { text: prompt };

        const response: GenerateContentResponse = await ai.models.generateContent({
            model: modelFlash,
            contents: { parts: [textPart, imagePart] },
            config: {
                systemInstruction: systemInstruction || defaultSystemInstruction,
            },
        });
        return response.text;
    } catch (error) {
        console.error("Error generating text with image:", error);
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.";
    }
};

export const generateQuiz = async (topic: string): Promise<any> => {
    try {
        const response = await ai.models.generateContent({
            model: modelFlash,
            contents: `Ø£Ù†Ø´Ø¦ Ø§Ø®ØªØ¨Ø§Ø±Ù‹Ø§ Ù…Ù† 10 Ø£Ø³Ø¦Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ Ø­ÙˆÙ„ Ù…ÙˆØ¶ÙˆØ¹ "${topic}" Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ù…ØµØ±. ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ ÙƒÙ„ Ø³Ø¤Ø§Ù„ Ø¹Ù„Ù‰ 4 Ø§Ø®ØªÙŠØ§Ø±Ø§ØªØŒ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©.`,
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        quiz: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.OBJECT,
                                properties: {
                                    question: { type: Type.STRING },
                                    options: {
                                        type: Type.ARRAY,
                                        items: { type: Type.STRING }
                                    },
                                    answer: { type: Type.STRING }
                                },
                                required: ["question", "options", "answer"]
                            }
                        }
                    },
                    required: ["quiz"]
                }
            }
        });

        const jsonString = response.text;
        return JSON.parse(jsonString);

    } catch (error) {
        console.error("Error generating quiz:", error);
        return null;
    }
};

export const generateMindMapMermaid = async (text: string): Promise<string> => {
    const prompt = `Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ø¨ØªÙ†Ø³ÙŠÙ‚ Mermaid.
    - Ø§Ø³ØªØ®Ø¯Ù… 'graph TD' Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø³ÙÙ„.
    - ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù‡ÙŠ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù†Øµ.
    - ØªÙØ±Ø¹ Ù…Ù† Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„ÙØ±Ø¹ÙŠØ©.
    - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù‡Ù… '-->' Ù„Ø±Ø¨Ø· Ø§Ù„Ø£ÙÙƒØ§Ø±.
    - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ø¹Ù‚Ø¯ (Ù…Ø«Ù„ Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ Ø§Ù„Ù…Ø³ØªØ¯ÙŠØ±Ø© ()ØŒ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„Ø© []ØŒ Ø§Ù„Ù…Ø¹ÙŠÙ† {}) Ù„ØªÙ…ÙŠÙŠØ² Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø£ÙÙƒØ§Ø±.
    - Ø§Ø¬Ø¹Ù„Ù‡Ø§ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ø¸Ù…Ø© ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù… Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø©.
    - Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù†Øµ ØªÙˆØ¶ÙŠØ­ÙŠ Ù‚Ø¨Ù„ Ø£Ùˆ Ø¨Ø¹Ø¯ ÙƒÙˆØ¯ Mermaid. Ø£Ø±Ø¬Ø¹ ÙƒÙˆØ¯ Mermaid ÙÙ‚Ø· Ø¯Ø§Ø®Ù„ \`\`\`mermaid ... \`\`\`.
    
    Ø§Ù„Ù†Øµ:
    ${text}`;

    try {
        const response: GenerateContentResponse = await ai.models.generateContent({
            model: modelFlash,
            contents: prompt,
            config: {
                systemInstruction: "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ø°Ù‡Ù†ÙŠØ© Ø¨ØªÙ†Ø³ÙŠÙ‚ Mermaid. Ù‡Ø¯ÙÙƒ Ù‡Ùˆ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¥Ù„Ù‰ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù†Ø¸Ù…Ø©.",
                responseMimeType: "text/plain",
            },
        });
        
        let mermaidCode = response.text.trim();
        
        const regex = /```(?:mermaid)?([\s\S]*?)```/;
        const match = mermaidCode.match(regex);

        if (match && match[1]) {
            mermaidCode = match[1].trim();
        } else {
            mermaidCode = mermaidCode.replace(/```(?:mermaid)?/g, '').replace(/```/g, '').trim();
        }

        if (!mermaidCode.toLowerCase().startsWith('graph')) {
             console.warn("Generated text doesn't look like a valid Mermaid graph:", mermaidCode);
             return "graph TD; A[Ø®Ø·Ø£] --> B[ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©ØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨];";
        }
        
        return mermaidCode;
    } catch (error) {
        console.error("Error generating mind map:", error);
        return "graph TD; A[Ø®Ø·Ø£] --> B[Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø°Ù‡Ù†ÙŠØ©];";
    }
};

export const analyzeYouTubeVideo = async (url: string, userPrompt: string): Promise<GenerateContentResponse> => {
    const prompt = `Ø¨ØµÙØªÙƒ Ø®Ø¨ÙŠØ±Ù‹Ø§ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ÙŠÙˆØªÙŠÙˆØ¨ Ø§Ù„ØªØ§Ù„ÙŠ. Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù„ Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø«Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ ÙˆØ§Ù„Ù†Øµ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (transcript) Ø¥Ù† ÙˆØ¬Ø¯.
    
    Ø±Ø§Ø¨Ø· Ø§Ù„ÙÙŠØ¯ÙŠÙˆ: ${url}
    
    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ: ${userPrompt}
    
    Ù‚Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø¸Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø©.`;

    const response = await generateText(
        prompt, 
        "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙ„Ø®ÙŠØµ ÙˆØ´Ø±Ø­ Ù…Ø­ØªÙˆÙ‰ ÙŠÙˆØªÙŠÙˆØ¨.",
        modelPro,
        {
            tools: [{googleSearch: {}}],
        }
    );
    return response;
};


// New features
export const generateImage = async (prompt: string, aspectRatio: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' ): Promise<string> => {
    try {
        const response = await ai.models.generateImages({
            model: 'imagen-4.0-generate-001',
            prompt: prompt,
            config: {
              numberOfImages: 1,
              outputMimeType: 'image/jpeg',
              aspectRatio,
            },
        });
        const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
        return `data:image/jpeg;base64,${base64ImageBytes}`;
    } catch (error) {
        console.error("Error generating image:", error);
        return '';
    }
};

export const editImage = async (prompt: string, imageFile: File): Promise<string> => {
    try {
        const imagePart = await fileToGenerativePart(imageFile);
        const textPart = { text: prompt };

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [imagePart, textPart] },
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });
        
        for (const part of response.candidates[0].content.parts) {
            if (part.inlineData) {
              const base64ImageBytes: string = part.inlineData.data;
              return `data:image/png;base64,${base64ImageBytes}`;
            }
        }
        return '';
    } catch (error) {
        console.error("Error editing image:", error);
        return '';
    }
};

export const generateTTSAudio = async (text: string): Promise<string | null> => {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash-preview-tts",
            contents: [{ parts: [{ text: `Say with a clear and helpful tone: ${text}` }] }],
            config: {
              responseModalities: [Modality.AUDIO],
              speechConfig: {
                  voiceConfig: {
                    prebuiltVoiceConfig: { voiceName: 'Kore' },
                  },
              },
            },
        });
        const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
        return base64Audio || null;
    } catch (error) {
        console.error("Error generating TTS audio:", error);
        return null;
    }
};

// Audio decoding utilities
export function decodeBase64(base64: string) {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes;
}
  
export async function decodeAudioData(
    data: Uint8Array,
    ctx: AudioContext,
    sampleRate: number = 24000, // TTS model sample rate
    numChannels: number = 1,
): Promise<AudioBuffer> {
    const dataInt16 = new Int16Array(data.buffer);
    const frameCount = dataInt16.length / numChannels;
    const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);
  
    for (let channel = 0; channel < numChannels; channel++) {
      const channelData = buffer.getChannelData(channel);
      for (let i = 0; i < frameCount; i++) {
        channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
      }
    }
    return buffer;
}